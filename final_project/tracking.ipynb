{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib\n",
    "import skimage\n",
    "\n",
    "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "End of video, breaking\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "cap_tracking = cv.VideoCapture(r\"..\\datasets\\unzipped\\endovis\\Tracking_Robotic_Training\\Training\\Dataset2\\Video.avi\")\n",
    "cap_segmentation = cv.VideoCapture(r\"..\\datasets\\unzipped\\endovis\\Segmentation_Robotic_Training\\Training\\Dataset2\\Segmentation.avi\")\n",
    "tracking_data = open(r\"..\\datasets\\unzipped\\endovis\\Tracking_Robotic_Training\\Training\\Dataset2\\Pose.txt\", \"r\")\n",
    "\n",
    "stop = False\n",
    "    \n",
    "frame_number = 0\n",
    "\n",
    "pred = []\n",
    "actual = []\n",
    "\n",
    "while True:\n",
    "    ret_seg, frame_seg = cap_segmentation.read()\n",
    "    if frame_seg is None:\n",
    "        print(\"End of video, breaking\")\n",
    "        break\n",
    "\n",
    "    frame_number += 1\n",
    "\n",
    "    gs = cv.cvtColor(frame_seg, code = cv.COLOR_BGR2GRAY)\n",
    "    im = gs\n",
    "\n",
    "    canny = cv.Canny(gs, 70, 160)\n",
    "    canny_blur = cv.GaussianBlur(canny, (3, 3), 1.0)\n",
    "\n",
    "    # calculate moments of binary image\n",
    "    M_shaft = cv.moments(cv.inRange(gs, 155, 165))\n",
    "    \n",
    "    # # calculate x,y coordinate of center\n",
    "    cX_shaft = int(M_shaft[\"m10\"] / M_shaft[\"m00\"])\n",
    "    cY_shaft = int(M_shaft[\"m01\"] / M_shaft[\"m00\"])\n",
    "    \n",
    "    # # put text and highlight the center\n",
    "    # cv.circle(frame_tracking, (cX_shaft, cY_shaft), 5, (0, 255, 0), -1)\n",
    "\n",
    "    # calculate moments of binary image\n",
    "    M_eef = cv.moments(cv.inRange(gs, 65, 75))\n",
    "    \n",
    "    # # calculate x,y coordinate of center\n",
    "    cX_eef = int(M_eef[\"m10\"] / M_eef[\"m00\"])\n",
    "    cY_eef = int(M_eef[\"m01\"] / M_eef[\"m00\"])\n",
    "\n",
    "    # cv.circle(frame_tracking, (cX_eef, cY_eef), 5, (0, 255, 0), -1)\n",
    "\n",
    "    # cv.line(frame_tracking, (cX_eef, cY_eef), (cX_shaft, cY_shaft), color = (0, 255, 0))\n",
    "\n",
    "    x, y = skimage.draw.line(cX_eef, cY_eef, cX_shaft, cY_shaft)\n",
    "    found = False\n",
    "    for i, j in zip(x, y):\n",
    "        if canny_blur[j,i] > 0: \n",
    "            found = True\n",
    "            break\n",
    "    \n",
    "    if not found:\n",
    "        i = j = -1\n",
    "        print((cX_eef, cY_eef), (cX_shaft, cY_shaft))\n",
    "        cv.line(canny_blur, (cX_eef, cY_eef), (cX_shaft, cY_shaft), color = 255)\n",
    "        plt.imshow(canny_blur)\n",
    "        \n",
    "        cv.waitKey(0)\n",
    "\n",
    "    vec = np.array([cX_shaft - cX_eef, -(cY_shaft - cY_eef)], dtype = np.float64)\n",
    "    vec /= np.linalg.norm(vec)\n",
    "    pred.append((i,j,-vec[0],vec[1]))\n",
    "    \n",
    "    vals = tracking_data.readline().split(\" \")[:4]\n",
    "    actual.append((int(vals[0]), int(vals[1]), float(vals[2]), float(vals[3])))\n",
    "\n",
    "    if frame_number % 100 == 0:\n",
    "        print(frame_number)\n",
    "\n",
    "    # cv.circle(frame_tracking, (i, j), 5, (255, 0, 0), -1)\n",
    "    # # 573 346\n",
    "    # cv.circle(frame_tracking, (521, 289), 5, (255, 255, 0), -1)\n",
    "\n",
    "    # put text and highlight the center\n",
    "\n",
    "\n",
    "\n",
    "    # # display the image\n",
    "    # cv.imshow(\"Image\", frame_tracking)\n",
    "    # cv.waitKey(0)\n",
    "\n",
    "# plt.imshow(grad, cmap = \"gray\")\n",
    "# plt.colorbar()\n",
    "# # cv.imshow('Frame', np.concatenate((value, masked_img_gray[:,:,0]), axis = 1))\n",
    "\n",
    "# frame_number += 1\n",
    "\n",
    "# while True:\n",
    "#     # Exit if 'q' is pressed\n",
    "#     if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "#         stop = True\n",
    "#         break\n",
    "#     elif cv.waitKey(1) == 32: \n",
    "#         break\n",
    "                                                                \n",
    "# cv.destroyAllWindows()\n",
    "# cap_segmentation.release()\n",
    "# cap_tracking.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14e4e442610>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot([x[0] for x in pred])\n",
    "plt.plot([x[1] for x in actual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14e49f55050>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot([np.degrees(np.arctan2(x[3], x[2])) for x in pred])\n",
    "plt.plot([np.degrees(np.arctan2(x[3], x[2])) for x in actual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m         stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m cv\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m33\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m32\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Now update the previous frame and previous points\u001b[39;00m\n\u001b[0;32m     83\u001b[0m old_gray \u001b[38;5;241m=\u001b[39m frame_gray\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cap = cv.VideoCapture(r\"..\\datasets\\unzipped\\endovis\\Tracking_Robotic_Training\\Training\\Dataset4\\Video.avi\")\n",
    "\n",
    "# # Feature parameters\n",
    "# feature_params = {\n",
    "#     \"maxCorners\": 100,\n",
    "#     \"qualityLevel\": 0.3,\n",
    "#     \"minDistance\": 7,\n",
    "#     \"blockSize\": 7 \n",
    "# }\n",
    "\n",
    "# # Lucas Kinade parameters\n",
    "# lk_params = {\n",
    "#     \"winSize\": (25, 25),\n",
    "#     \"maxLevel\": 4,\n",
    "#     \"criteria\": (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "# }\n",
    "\n",
    "# # Create some random colors\n",
    "# color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# # Take first frame and find corners in it\n",
    "# ret, old_frame = cap.read()\n",
    "# old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
    "# p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "# # Create a mask image for drawing purposes\n",
    "# mask = np.zeros_like(old_frame)\n",
    "\n",
    "# # Initialize flag to end viewing when q is pressed\n",
    "# stop = False\n",
    "\n",
    "# frame_number = 0\n",
    "\n",
    "# while (not stop):\n",
    "#     ret,frame = cap.read()\n",
    "#     if frame is None:\n",
    "#         print(\"End of video, breaking\")\n",
    "#         break\n",
    "    \n",
    "#     frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # calculate optical flow\n",
    "#     p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "#     if p1 is None: \n",
    "#         print(\"Failed to extract features\")\n",
    "#         continue\n",
    "\n",
    "#     # Select good points\n",
    "#     good_new = p1[st==1]\n",
    "#     good_old = p0[st==1]\n",
    "    \n",
    "#     try:\n",
    "#         # Draw the tracks\n",
    "#         for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "#             a,b = new.ravel()\n",
    "#             c,d = old.ravel()\n",
    "            \n",
    "#             # Set values to integers to allow for drawing\n",
    "#             a = int(a)\n",
    "#             b = int(b)\n",
    "#             c = int(c)\n",
    "#             d = int(d)\n",
    "\n",
    "#             mask = cv.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "#             frame = cv.circle(frame, (a,b), 5, color[i].tolist(), -1)\n",
    "            \n",
    "#         img = cv.add(frame,mask)\n",
    "        \n",
    "#         cv.imshow('Frame', img)\n",
    "#         # cv.imwrite(os.path.join(PATH, f\"vid_{ii}_{frame_number}.png\"), img)\n",
    "        \n",
    "#         frame_number += 1\n",
    "        \n",
    "#         while True:\n",
    "#             # Exit if 'q' is pressed\n",
    "#             if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "#                 stop = True\n",
    "#                 break\n",
    "#             elif cv.waitKey(33) == 32: break\n",
    "                                                                    \n",
    "#         # Now update the previous frame and previous points\n",
    "#         old_gray = frame_gray.copy()\n",
    "#         p0 = good_new.reshape(-1,1,2)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Iteration failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
